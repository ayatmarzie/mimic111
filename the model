1
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.sequence import pad_sequences

# Load dataset
df = pd.read_csv("your_dataset.csv")

# Define column index ranges
temporal_range = list(range(500))  # First 500 columns = temporal data
static_range = list(range(500, 510))  # Last 10 columns = static data
label_index = 510  # Last column = labels

# Extract feature data
X_temporal = df.iloc[:, temporal_range].values
X_static = df.iloc[:, static_range].values
y = df.iloc[:, label_index].values

# Convert labels to categorical (for classification)
y = to_categorical(y)

# Reshape temporal data into sequences
num_patients = len(df["hadmid"].unique())  # Unique patients
time_steps = X_temporal.shape[0] // num_patients  # Time steps per patient
X_temporal = X_temporal.reshape(num_patients, time_steps, -1)

# Train-test split
X_temporal_train, X_temporal_test, X_static_train, X_static_test, y_train, y_test = train_test_split(
    X_temporal, X_static, y, test_size=0.2, random_state=42
)

# Print shapes
print(f"Train temporal shape: {X_temporal_train.shape}")  # (num_train, time_steps, num_features)
print(f"Train static shape: {X_static_train.shape}")  # (num_train, num_static_features)
print(f"Train labels shape: {y_train.shape}")  # (num_train, num_classes)



2



import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, LSTM, Dense, Concatenate
from tensorflow.keras.optimizers import Adam

# Define input shapes
time_steps = X_temporal.shape[1]
num_temporal_features = X_temporal.shape[2]
num_static_features = X_static.shape[1]
num_classes = y.shape[1]  # Number of output classes

# Temporal input (LSTM)
temporal_input = Input(shape=(time_steps, num_temporal_features), name="temporal_input")
lstm_out = LSTM(64, return_sequences=False, name="lstm_layer")(temporal_input)

# Non-temporal input (Dense)
static_input = Input(shape=(num_static_features,), name="static_input")
static_out = Dense(32, activation="relu", name="static_dense")(static_input)

# Merge LSTM and Dense outputs
merged = Concatenate(name="concatenation")([lstm_out, static_out])
output = Dense(num_classes, activation="softmax", name="output_layer")(merged)  # Softmax for multi-class

# Define and compile the model
model = Model(inputs=[temporal_input, static_input], outputs=output)
model.compile(optimizer=Adam(learning_rate=0.001), loss="categorical_crossentropy", metrics=["accuracy"])

# Train the model in batches
batch_size = 32
model.fit(
    [X_temporal_train, X_static_train], y_train,
    validation_data=([X_temporal_test, X_static_test], y_test),
    epochs=20, batch_size=batch_size
)




3

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc
import matplotlib.pyplot as plt

# Predict probabilities
y_train_pred = model.predict([X_temporal_train, X_static_train])
y_test_pred = model.predict([X_temporal_test, X_static_test])

# Convert probabilities to class labels
y_train_pred_labels = np.argmax(y_train_pred, axis=1)
y_test_pred_labels = np.argmax(y_test_pred, axis=1)

# Convert categorical y back to labels
y_train_true = np.argmax(y_train, axis=1)
y_test_true = np.argmax(y_test, axis=1)

# Compute metrics
train_accuracy = accuracy_score(y_train_true, y_train_pred_labels)
test_accuracy = accuracy_score(y_test_true, y_test_pred_labels)

train_precision = precision_score(y_train_true, y_train_pred_labels, average="weighted")
test_precision = precision_score(y_test_true, y_test_pred_labels, average="weighted")

train_recall = recall_score(y_train_true, y_train_pred_labels, average="weighted")
test_recall = recall_score(y_test_true, y_test_pred_labels, average="weighted")

train_f1 = f1_score(y_train_true, y_train_pred_labels, average="weighted")
test_f1 = f1_score(y_test_true, y_test_pred_labels, average="weighted")

# Print results
print(f"Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}")
print(f"Train Precision: {train_precision:.4f}, Test Precision: {test_precision:.4f}")
print(f"Train Recall: {train_recall:.4f}, Test Recall: {test_recall:.4f}")
print(f"Train F1 Score: {train_f1:.4f}, Test F1 Score: {test_f1:.4f}")

# Compute ROC Curve
y_test_prob = y_test_pred[:, 1]  # Probabilities for class 1
fpr, tpr, _ = roc_curve(y_test_true, y_test_prob)
roc_auc = auc(fpr, tpr)

# Plot ROC Curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color="blue", label=f"ROC Curve (area = {roc_auc:.4f})")
plt.plot([0, 1], [0, 1], color="gray", linestyle="--")  # Diagonal line
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("Receiver Operating Characteristic (ROC) Curve")
plt.legend()
plt.show()
